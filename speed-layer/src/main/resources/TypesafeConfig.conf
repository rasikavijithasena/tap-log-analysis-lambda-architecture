application {
  appName = "com.hsenidmobile.spark.analytics.SparkBatch";
  master = "local[2]"
  duration = 1000
  hiveConf = "hdfs://quickstart.cloudera:8020/user/hive/warehouse"
  thriftConf = "thrift://quickstart.cloudera:9083"
  shuffle = 2
  parellelismPartitions = 6
  checkpointDirectory = "/home/cloudera/Documents/checkpoints"
  networkTimeout = "600s"
}


input {
  directory1 = "/home/cloudera/Downloads/rasika/sdp-log"
  directory = "hdfs://localhost:8020/user/hive/warehouse/transaction_logs"
  fieldCount = 60
  delimeter = "\\|"
  fields = "id,time_stamp,sp_id,service_provider,app_id,app_name,state_app,source_entity_address,source_entity_masked,channel_type,source_protocol,dest_address,dest_masked,dest_channel_type,dest_protocol,travel_direction,ncs,billing,part_entity_type,charge_amount,currency,exchange_rates,charging_service_code,msisdn, masked_msisdn,billing_event,response_code,response_desc,transaction_state, transaction_keyword,request_receive,operator_name,configured_charge_amount,percentage_message,sp_revenue,ad_name,ad_content,multiple_recipient,overall_status_mt,overall_response_mt,trans_id_pgw,charging_type,number_masked,order_number_passed,invoice_number_passed,external_id_passed,session_id_ussd,ussd_oper_type,balance_sp,total_amount_sp,col_51,col_52,col_53,col_54,col_55,col_56,col_57,col_58,col_59,col_60"
  fieldSeperator = ","
  //selectedFields = ["time_stamp","app_id","channel_type","travel_direction" ]      //
  //schemaString = "time_stamp,app_id,channel_type,travel_direction"                  ///////
  selectedFields = ["time_stamp","sp_id","ncs","operator_name", "sp_revenue","total_amount_sp" ]      //
  schemaString = "time_stamp,sp_id,ncs,operator_name,sp_revenue,total_amount_sp"

  time_stamp {
    fieldNumber = 2
    substring = true
    substringValue = [0,10]

  }

  sp_id {
    fieldNumber = 3
    substring = false
  }

  app_id {
    fieldNumber = 5
    substring = false
  }

  ncs {
    fieldNumber = 17
    substring = false
  }

  channel_type {
    fieldNumber = 10
    substring = false
  }

  travel_direction {
    fieldNumber = 16
    substring = false
  }

  operator_name {
    fieldNumber = 32
    substring = false
  }

  sp_revenue {
    fieldNumber = 35
    substring = false
  }

  total_amount_sp {
    fieldNumber = 50
    substring = false
  }


}

query {
  //selectedFields = "time_stamp,app_id,channel_type,travel_direction"     //
  selectedFields = "time_stamp,sp_id,ncs,operator_name,sp_revenue,total_amount_sp"
  whereClause = "channel_type = 'sms' AND travel_direction = 'mt'"
  groupingFields = ["time_stamp", "app_id"]
  groupingFieldsAsString = "time_stamp,app_id"
  //finalColumns = "time_stamp,app_id,count"
  finalColumns = "time_stamp,sp_id,ncs,operator_name,sp_revenue,total_amount_sp"
}

queryForReport {
  selectedFields = "time_stamp,sp_id,ncs,operator_name,sp_revenue,total_amount_sp"
}

output {
  tableName = "daily_summary"
  temporyView = "temp_view"
  columnNames = "time_stamp, app_id, count"
  numberOfColumns = 3
  createTableQuery = "time_stamp String, app_id String, count String"

}

kafka {
  brokers = "localhost:9092"
  topicSet = "test"
  topicSetSeperator = ","
  bootstrapServers = "localhost:9092,anotherhost:9092"
  groupId = "sparkKafka"
}

batch {
  outputFormat = "parquet"
  path1 = "/home/cloudera/Desktop/batchData1.parquet"
  path = "hdfs://quickstart.cloudera:8020/user/cloudera/spark/batch/second1"
}

structured {
  format = "parquet"
  parquet {
    parquetPath = "hdfs://quickstart.cloudera:8020/user/cloudera/spark/speed/parquet"
    parquetPath1 = "/home/cloudera/Desktop/par"
    checkpointPath = "hdfs://quickstart.cloudera:8020/user/cloudera/spark/speed/checkpoints"
    checkpointPath1 = "/home/cloudera/Documents/checkpoints"
  }

}
